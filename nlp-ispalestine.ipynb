{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1874598,"sourceType":"datasetVersion","datasetId":1115942},{"sourceId":4855502,"sourceType":"datasetVersion","datasetId":2814684},{"sourceId":6476455,"sourceType":"datasetVersion","datasetId":3741302},{"sourceId":6477512,"sourceType":"datasetVersion","datasetId":3742034},{"sourceId":6935927,"sourceType":"datasetVersion","datasetId":3982915}],"dockerImageVersionId":30498,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Use TfidfVectorizer to convert text data into numerical features\nvectorizer = TfidfVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Initialize and train the Naive Bayes model\nmodel = MultinomialNB()\nmodel.fit(X_train_tfidf, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test_tfidf)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n# Display classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:03:25.628925Z","iopub.execute_input":"2023-12-07T05:03:25.629704Z","iopub.status.idle":"2023-12-07T05:03:25.671194Z","shell.execute_reply.started":"2023-12-07T05:03:25.629671Z","shell.execute_reply":"2023-12-07T05:03:25.670284Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Accuracy: 0.78\nClassification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.97      0.82        37\ncautiously optimistic       0.83      0.59      0.69        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.44      0.62         9\n             positive       0.77      0.81      0.79        21\n\n             accuracy                           0.78       100\n            macro avg       0.86      0.70      0.75       100\n         weighted avg       0.82      0.78      0.77       100\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Use TfidfVectorizer to convert text data into numerical features\nvectorizer = TfidfVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Initialize and train the Support Vector Machine (SVM) model\nsvm_model = SVC(kernel='linear')  # You can try different kernels, e.g., 'linear', 'rbf', etc.\nsvm_model.fit(X_train_tfidf, y_train)\n\n# Make predictions on the test set\ny_pred_svm = svm_model.predict(X_test_tfidf)\n\n# Evaluate the SVM model\naccuracy_svm = accuracy_score(y_test, y_pred_svm)\nprint(f\"SVM Accuracy: {accuracy_svm:.2f}\")\n\n# Display SVM classification report\nprint(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:06:13.628604Z","iopub.execute_input":"2023-12-07T05:06:13.629404Z","iopub.status.idle":"2023-12-07T05:06:13.769573Z","shell.execute_reply.started":"2023-12-07T05:06:13.629369Z","shell.execute_reply":"2023-12-07T05:06:13.768582Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"SVM Accuracy: 0.87\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      1.00      0.87        37\ncautiously optimistic       0.88      0.88      0.88        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.78      0.88         9\n             positive       1.00      0.81      0.89        21\n\n             accuracy                           0.87       100\n            macro avg       0.93      0.83      0.87       100\n         weighted avg       0.90      0.87      0.87       100\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Use TfidfVectorizer to convert text data into numerical features\nvectorizer = TfidfVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Multinomial Naive Bayes': MultinomialNB(),\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear')\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_tfidf, y_train)\n    y_pred = clf.predict(X_test_tfidf)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:07:48.309207Z","iopub.execute_input":"2023-12-07T05:07:48.309608Z","iopub.status.idle":"2023-12-07T05:07:50.305126Z","shell.execute_reply.started":"2023-12-07T05:07:48.309581Z","shell.execute_reply":"2023-12-07T05:07:50.304185Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Multinomial Naive Bayes Accuracy: 0.78\nMultinomial Naive Bayes Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.97      0.82        37\ncautiously optimistic       0.83      0.59      0.69        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.44      0.62         9\n             positive       0.77      0.81      0.79        21\n\n             accuracy                           0.78       100\n            macro avg       0.86      0.70      0.75       100\n         weighted avg       0.82      0.78      0.77       100\n\n==================================================\nLogistic Regression Accuracy: 0.81\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.70      1.00      0.82        37\ncautiously optimistic       0.86      0.71      0.77        17\n             negative       1.00      0.56      0.72        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.94      0.76      0.84        21\n\n             accuracy                           0.81       100\n            macro avg       0.90      0.76      0.81       100\n         weighted avg       0.85      0.81      0.81       100\n\n==================================================\nRandom Forest Accuracy: 0.82\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.72      0.97      0.83        37\ncautiously optimistic       0.87      0.76      0.81        17\n             negative       1.00      0.50      0.67        16\n              neutral       1.00      0.89      0.94         9\n             positive       0.89      0.81      0.85        21\n\n             accuracy                           0.82       100\n            macro avg       0.90      0.79      0.82       100\n         weighted avg       0.85      0.82      0.81       100\n\n==================================================\nGradient Boosting Accuracy: 0.81\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      0.92      0.84        37\ncautiously optimistic       0.92      0.65      0.76        17\n             negative       1.00      0.69      0.81        16\n              neutral       0.70      0.78      0.74         9\n             positive       0.78      0.86      0.82        21\n\n             accuracy                           0.81       100\n            macro avg       0.83      0.78      0.79       100\n         weighted avg       0.83      0.81      0.81       100\n\n==================================================\nSVM Accuracy: 0.87\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      1.00      0.87        37\ncautiously optimistic       0.88      0.88      0.88        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.78      0.88         9\n             positive       1.00      0.81      0.89        21\n\n             accuracy                           0.87       100\n            macro avg       0.93      0.83      0.87       100\n         weighted avg       0.90      0.87      0.87       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Use TfidfVectorizer to convert text data into numerical features\nvectorizer = TfidfVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Multinomial Naive Bayes': MultinomialNB(),\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_tfidf, y_train)\n    y_pred = clf.predict(X_test_tfidf)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:09:14.835909Z","iopub.execute_input":"2023-12-07T05:09:14.836976Z","iopub.status.idle":"2023-12-07T05:09:17.313441Z","shell.execute_reply.started":"2023-12-07T05:09:14.836938Z","shell.execute_reply":"2023-12-07T05:09:17.312498Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Multinomial Naive Bayes Accuracy: 0.78\nMultinomial Naive Bayes Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.97      0.82        37\ncautiously optimistic       0.83      0.59      0.69        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.44      0.62         9\n             positive       0.77      0.81      0.79        21\n\n             accuracy                           0.78       100\n            macro avg       0.86      0.70      0.75       100\n         weighted avg       0.82      0.78      0.77       100\n\n==================================================\nLogistic Regression Accuracy: 0.81\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.70      1.00      0.82        37\ncautiously optimistic       0.86      0.71      0.77        17\n             negative       1.00      0.56      0.72        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.94      0.76      0.84        21\n\n             accuracy                           0.81       100\n            macro avg       0.90      0.76      0.81       100\n         weighted avg       0.85      0.81      0.81       100\n\n==================================================\nRandom Forest Accuracy: 0.83\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.75      0.97      0.85        37\ncautiously optimistic       0.93      0.76      0.84        17\n             negative       1.00      0.56      0.72        16\n              neutral       0.80      0.89      0.84         9\n             positive       0.89      0.81      0.85        21\n\n             accuracy                           0.83       100\n            macro avg       0.87      0.80      0.82       100\n         weighted avg       0.86      0.83      0.83       100\n\n==================================================\nGradient Boosting Accuracy: 0.81\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      0.92      0.84        37\ncautiously optimistic       0.92      0.65      0.76        17\n             negative       1.00      0.69      0.81        16\n              neutral       0.70      0.78      0.74         9\n             positive       0.78      0.86      0.82        21\n\n             accuracy                           0.81       100\n            macro avg       0.83      0.78      0.79       100\n         weighted avg       0.83      0.81      0.81       100\n\n==================================================\nSVM Accuracy: 0.87\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      1.00      0.87        37\ncautiously optimistic       0.88      0.88      0.88        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.78      0.88         9\n             positive       1.00      0.81      0.89        21\n\n             accuracy                           0.87       100\n            macro avg       0.93      0.83      0.87       100\n         weighted avg       0.90      0.87      0.87       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.80\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      0.92      0.84        37\ncautiously optimistic       0.86      0.71      0.77        17\n             negative       0.92      0.69      0.79        16\n              neutral       0.67      0.67      0.67         9\n             positive       0.81      0.81      0.81        21\n\n             accuracy                           0.80       100\n            macro avg       0.80      0.76      0.78       100\n         weighted avg       0.81      0.80      0.80       100\n\n==================================================\nDecision Tree Accuracy: 0.73\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.75      0.81      0.78        37\ncautiously optimistic       0.75      0.71      0.73        17\n             negative       0.75      0.56      0.64        16\n              neutral       0.58      0.78      0.67         9\n             positive       0.75      0.71      0.73        21\n\n             accuracy                           0.73       100\n            macro avg       0.72      0.71      0.71       100\n         weighted avg       0.73      0.73      0.73       100\n\n==================================================\nAdaBoost Accuracy: 0.48\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.54      0.95      0.69        37\ncautiously optimistic       0.23      0.29      0.26        17\n             negative       0.00      0.00      0.00        16\n              neutral       0.88      0.78      0.82         9\n             positive       0.33      0.05      0.08        21\n\n             accuracy                           0.48       100\n            macro avg       0.39      0.41      0.37       100\n         weighted avg       0.39      0.48      0.39       100\n\n==================================================\nBagging Classifier Accuracy: 0.78\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.74      0.95      0.83        37\ncautiously optimistic       0.79      0.65      0.71        17\n             negative       0.75      0.56      0.64        16\n              neutral       0.89      0.89      0.89         9\n             positive       0.83      0.71      0.77        21\n\n             accuracy                           0.78       100\n            macro avg       0.80      0.75      0.77       100\n         weighted avg       0.78      0.78      0.77       100\n\n==================================================\nExtra Trees Accuracy: 0.86\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.79      1.00      0.88        37\ncautiously optimistic       0.88      0.82      0.85        17\n             negative       1.00      0.69      0.81        16\n              neutral       0.88      0.78      0.82         9\n             positive       0.94      0.81      0.87        21\n\n             accuracy                           0.86       100\n            macro avg       0.90      0.82      0.85       100\n         weighted avg       0.88      0.86      0.86       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n\n# Use TfidfVectorizer to convert text data into numerical features\nvectorizer = TfidfVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Multinomial Naive Bayes': MultinomialNB(),\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_tfidf, y_train)\n    y_pred = clf.predict(X_test_tfidf)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:14:44.517401Z","iopub.execute_input":"2023-12-07T05:14:44.517822Z","iopub.status.idle":"2023-12-07T05:14:46.902180Z","shell.execute_reply.started":"2023-12-07T05:14:44.517788Z","shell.execute_reply":"2023-12-07T05:14:46.901205Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Multinomial Naive Bayes Accuracy: 0.85\nMultinomial Naive Bayes Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.72      1.00      0.84        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.95      0.90      0.92        20\n              neutral       1.00      0.50      0.67        12\n             positive       0.86      0.83      0.84        23\n\n             accuracy                           0.85       100\n            macro avg       0.89      0.81      0.83       100\n         weighted avg       0.87      0.85      0.85       100\n\n==================================================\nLogistic Regression Accuracy: 0.89\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.74      1.00      0.85        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.95      0.90      0.92        20\n              neutral       1.00      0.83      0.91        12\n             positive       1.00      0.83      0.90        23\n\n             accuracy                           0.89       100\n            macro avg       0.93      0.88      0.90       100\n         weighted avg       0.91      0.89      0.89       100\n\n==================================================\nRandom Forest Accuracy: 0.87\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.73      0.92      0.81        26\ncautiously optimistic       0.89      0.89      0.89        19\n             negative       1.00      0.80      0.89        20\n              neutral       0.91      0.83      0.87        12\n             positive       0.95      0.87      0.91        23\n\n             accuracy                           0.87       100\n            macro avg       0.90      0.86      0.88       100\n         weighted avg       0.89      0.87      0.87       100\n\n==================================================\nGradient Boosting Accuracy: 0.88\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.88      0.85      0.86        26\ncautiously optimistic       0.80      0.84      0.82        19\n             negative       0.90      0.90      0.90        20\n              neutral       0.77      0.83      0.80        12\n             positive       1.00      0.96      0.98        23\n\n             accuracy                           0.88       100\n            macro avg       0.87      0.88      0.87       100\n         weighted avg       0.88      0.88      0.88       100\n\n==================================================\nSVM Accuracy: 0.90\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.79      1.00      0.88        26\ncautiously optimistic       0.89      0.84      0.86        19\n             negative       0.95      0.90      0.92        20\n              neutral       1.00      0.83      0.91        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.90       100\n            macro avg       0.92      0.89      0.90       100\n         weighted avg       0.91      0.90      0.90       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.87\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.76      0.96      0.85        26\ncautiously optimistic       0.85      0.89      0.87        19\n             negative       0.94      0.85      0.89        20\n              neutral       1.00      0.75      0.86        12\n             positive       0.95      0.83      0.88        23\n\n             accuracy                           0.87       100\n            macro avg       0.90      0.86      0.87       100\n         weighted avg       0.89      0.87      0.87       100\n\n==================================================\nDecision Tree Accuracy: 0.81\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.79      0.88      0.84        26\ncautiously optimistic       0.87      0.68      0.76        19\n             negative       0.70      0.80      0.74        20\n              neutral       0.85      0.92      0.88        12\n             positive       0.90      0.78      0.84        23\n\n             accuracy                           0.81       100\n            macro avg       0.82      0.81      0.81       100\n         weighted avg       0.82      0.81      0.81       100\n\n==================================================\nAdaBoost Accuracy: 0.53\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.36      0.92      0.52        26\ncautiously optimistic       0.60      0.16      0.25        19\n             negative       0.00      0.00      0.00        20\n              neutral       0.83      0.83      0.83        12\n             positive       1.00      0.70      0.82        23\n\n             accuracy                           0.53       100\n            macro avg       0.56      0.52      0.48       100\n         weighted avg       0.54      0.53      0.47       100\n\n==================================================\nBagging Classifier Accuracy: 0.79\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.76      0.73      0.75        26\ncautiously optimistic       0.80      0.84      0.82        19\n             negative       0.82      0.70      0.76        20\n              neutral       0.73      0.92      0.81        12\n             positive       0.83      0.83      0.83        23\n\n             accuracy                           0.79       100\n            macro avg       0.79      0.80      0.79       100\n         weighted avg       0.79      0.79      0.79       100\n\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Extra Trees Accuracy: 0.89\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      0.92      0.84        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.95      0.95      0.95        20\n              neutral       0.83      0.83      0.83        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.89       100\n            macro avg       0.90      0.88      0.89       100\n         weighted avg       0.90      0.89      0.89       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n\n# Use CountVectorizer to convert text data into numerical features\nvectorizer = CountVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_count = vectorizer.fit_transform(X_train)\nX_test_count = vectorizer.transform(X_test)\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Multinomial Naive Bayes': MultinomialNB(),\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_count, y_train)\n    y_pred = clf.predict(X_test_count)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:17:03.069633Z","iopub.execute_input":"2023-12-07T05:17:03.070065Z","iopub.status.idle":"2023-12-07T05:17:05.022260Z","shell.execute_reply.started":"2023-12-07T05:17:03.070034Z","shell.execute_reply":"2023-12-07T05:17:05.021357Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Multinomial Naive Bayes Accuracy: 0.88\nMultinomial Naive Bayes Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.80      0.92      0.86        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.83      0.95      0.88        20\n              neutral       1.00      0.83      0.91        12\n             positive       0.95      0.83      0.88        23\n\n             accuracy                           0.88       100\n            macro avg       0.90      0.87      0.88       100\n         weighted avg       0.89      0.88      0.88       100\n\n==================================================\nLogistic Regression Accuracy: 0.89\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.78      0.96      0.86        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.90      0.90      0.90        20\n              neutral       0.91      0.83      0.87        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.89       100\n            macro avg       0.91      0.88      0.89       100\n         weighted avg       0.90      0.89      0.89       100\n\n==================================================\nRandom Forest Accuracy: 0.91\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.76      0.96      0.85        26\ncautiously optimistic       1.00      0.89      0.94        19\n             negative       1.00      0.90      0.95        20\n              neutral       0.91      0.83      0.87        12\n             positive       1.00      0.91      0.95        23\n\n             accuracy                           0.91       100\n            macro avg       0.93      0.90      0.91       100\n         weighted avg       0.93      0.91      0.91       100\n\n==================================================\nGradient Boosting Accuracy: 0.89\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.86      0.92      0.89        26\ncautiously optimistic       0.76      0.84      0.80        19\n             negative       0.90      0.95      0.93        20\n              neutral       1.00      0.83      0.91        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.89       100\n            macro avg       0.90      0.88      0.89       100\n         weighted avg       0.90      0.89      0.89       100\n\n==================================================\nSVM Accuracy: 0.87\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.79      0.88      0.84        26\ncautiously optimistic       0.80      0.84      0.82        19\n             negative       0.95      0.90      0.92        20\n              neutral       0.83      0.83      0.83        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.87       100\n            macro avg       0.87      0.87      0.87       100\n         weighted avg       0.88      0.87      0.87       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.77\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.73      0.85      0.79        26\ncautiously optimistic       0.78      0.74      0.76        19\n             negative       0.82      0.70      0.76        20\n              neutral       0.80      0.67      0.73        12\n             positive       0.76      0.83      0.79        23\n\n             accuracy                           0.77       100\n            macro avg       0.78      0.76      0.76       100\n         weighted avg       0.77      0.77      0.77       100\n\n==================================================\nDecision Tree Accuracy: 0.84\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.83      0.96      0.89        26\ncautiously optimistic       0.76      0.68      0.72        19\n             negative       0.88      0.75      0.81        20\n              neutral       0.77      0.83      0.80        12\n             positive       0.91      0.91      0.91        23\n\n             accuracy                           0.84       100\n            macro avg       0.83      0.83      0.83       100\n         weighted avg       0.84      0.84      0.84       100\n\n==================================================\nAdaBoost Accuracy: 0.54\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.43      0.85      0.57        26\ncautiously optimistic       0.60      0.32      0.41        19\n             negative       0.62      0.50      0.56        20\n              neutral       0.58      0.58      0.58        12\n             positive       0.82      0.39      0.53        23\n\n             accuracy                           0.54       100\n            macro avg       0.61      0.53      0.53       100\n         weighted avg       0.61      0.54      0.53       100\n\n==================================================\nBagging Classifier Accuracy: 0.87\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      0.88      0.82        26\ncautiously optimistic       0.89      0.84      0.86        19\n             negative       0.86      0.90      0.88        20\n              neutral       0.91      0.83      0.87        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.87       100\n            macro avg       0.88      0.87      0.87       100\n         weighted avg       0.88      0.87      0.87       100\n\n==================================================\nExtra Trees Accuracy: 0.88\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.75      0.92      0.83        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.95      0.90      0.92        20\n              neutral       0.83      0.83      0.83        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.88       100\n            macro avg       0.89      0.87      0.88       100\n         weighted avg       0.89      0.88      0.88       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom gensim.models import Word2Vec\nfrom gensim.models.doc2vec import TaggedDocument\nfrom nltk.tokenize import word_tokenize\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Tokenize the text data\ntokenized_X_train = [word_tokenize(text) for text in X_train]\ntokenized_X_test = [word_tokenize(text) for text in X_test]\n\n# Train Word2Vec model\nword2vec_model = Word2Vec(sentences=tokenized_X_train, vector_size=100, window=5, min_count=1, workers=4)\n\n# Function to create document vectors using Word2Vec model\ndef create_doc_vectors(tokenized_text, model):\n    vectors = [model.wv[word] for word in tokenized_text if word in model.wv]\n    return sum(vectors) / len(vectors) if vectors else [0] * model.vector_size\n\n# Create document vectors for training and testing sets\nX_train_w2v = [create_doc_vectors(tokens, word2vec_model) for tokens in tokenized_X_train]\nX_test_w2v = [create_doc_vectors(tokens, word2vec_model) for tokens in tokenized_X_test]\n\n# Convert to numpy arrays\nX_train_w2v = pd.DataFrame(X_train_w2v).to_numpy()\nX_test_w2v = pd.DataFrame(X_test_w2v).to_numpy()\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_w2v, y_train)\n    y_pred = clf.predict(X_test_w2v)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:18:45.427457Z","iopub.execute_input":"2023-12-07T05:18:45.428093Z","iopub.status.idle":"2023-12-07T05:18:51.788853Z","shell.execute_reply.started":"2023-12-07T05:18:45.428060Z","shell.execute_reply":"2023-12-07T05:18:51.787867Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Logistic Regression Accuracy: 0.33\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.37      0.84      0.52        37\ncautiously optimistic       0.00      0.00      0.00        17\n             negative       0.00      0.00      0.00        16\n              neutral       0.00      0.00      0.00         9\n             positive       0.12      0.10      0.11        21\n\n             accuracy                           0.33       100\n            macro avg       0.10      0.19      0.12       100\n         weighted avg       0.16      0.33      0.21       100\n\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Random Forest Accuracy: 0.67\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.67      0.81      0.73        37\ncautiously optimistic       0.82      0.53      0.64        17\n             negative       0.73      0.50      0.59        16\n              neutral       0.40      0.67      0.50         9\n             positive       0.78      0.67      0.72        21\n\n             accuracy                           0.67       100\n            macro avg       0.68      0.63      0.64       100\n         weighted avg       0.70      0.67      0.67       100\n\n==================================================\nGradient Boosting Accuracy: 0.66\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.74      0.76      0.75        37\ncautiously optimistic       0.55      0.65      0.59        17\n             negative       0.64      0.44      0.52        16\n              neutral       0.45      0.56      0.50         9\n             positive       0.75      0.71      0.73        21\n\n             accuracy                           0.66       100\n            macro avg       0.63      0.62      0.62       100\n         weighted avg       0.67      0.66      0.66       100\n\n==================================================\nSVM Accuracy: 0.37\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.37      1.00      0.54        37\ncautiously optimistic       0.00      0.00      0.00        17\n             negative       0.00      0.00      0.00        16\n              neutral       0.00      0.00      0.00         9\n             positive       0.00      0.00      0.00        21\n\n             accuracy                           0.37       100\n            macro avg       0.07      0.20      0.11       100\n         weighted avg       0.14      0.37      0.20       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.51\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.53      0.65      0.59        37\ncautiously optimistic       0.44      0.41      0.42        17\n             negative       0.55      0.38      0.44        16\n              neutral       0.25      0.33      0.29         9\n             positive       0.69      0.52      0.59        21\n\n             accuracy                           0.51       100\n            macro avg       0.49      0.46      0.47       100\n         weighted avg       0.53      0.51      0.51       100\n\n==================================================\nDecision Tree Accuracy: 0.57\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.67      0.59      0.63        37\ncautiously optimistic       0.45      0.53      0.49        17\n             negative       0.62      0.50      0.55        16\n              neutral       0.38      0.67      0.48         9\n             positive       0.67      0.57      0.62        21\n\n             accuracy                           0.57       100\n            macro avg       0.55      0.57      0.55       100\n         weighted avg       0.60      0.57      0.58       100\n\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"AdaBoost Accuracy: 0.38\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.45      0.54      0.49        37\ncautiously optimistic       0.26      0.35      0.30        17\n             negative       0.36      0.31      0.33        16\n              neutral       0.20      0.22      0.21         9\n             positive       0.56      0.24      0.33        21\n\n             accuracy                           0.38       100\n            macro avg       0.37      0.33      0.33       100\n         weighted avg       0.40      0.38      0.38       100\n\n==================================================\nBagging Classifier Accuracy: 0.63\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.63      0.73      0.68        37\ncautiously optimistic       0.56      0.59      0.57        17\n             negative       0.73      0.50      0.59        16\n              neutral       0.50      0.56      0.53         9\n             positive       0.72      0.62      0.67        21\n\n             accuracy                           0.63       100\n            macro avg       0.63      0.60      0.61       100\n         weighted avg       0.64      0.63      0.63       100\n\n==================================================\nExtra Trees Accuracy: 0.65\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.64      0.81      0.71        37\ncautiously optimistic       0.90      0.53      0.67        17\n             negative       0.60      0.38      0.46        16\n              neutral       0.40      0.67      0.50         9\n             positive       0.78      0.67      0.72        21\n\n             accuracy                           0.65       100\n            macro avg       0.66      0.61      0.61       100\n         weighted avg       0.68      0.65      0.65       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Load Universal Sentence Encoder\nembed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n\n# Create embeddings for training and testing sets\nX_train_use = embed(X_train)\nX_test_use = embed(X_test)\n\n# Convert TensorFlow tensors to NumPy arrays\nX_train_use = X_train_use.numpy()\nX_test_use = X_test_use.numpy()\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_use, y_train)\n    y_pred = clf.predict(X_test_use)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:21:14.764373Z","iopub.execute_input":"2023-12-07T05:21:14.765113Z","iopub.status.idle":"2023-12-07T05:21:48.011132Z","shell.execute_reply.started":"2023-12-07T05:21:14.765077Z","shell.execute_reply":"2023-12-07T05:21:48.010233Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Logistic Regression Accuracy: 0.79\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.86      0.78        37\ncautiously optimistic       0.71      0.71      0.71        17\n             negative       0.91      0.62      0.74        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.90      0.86      0.88        21\n\n             accuracy                           0.79       100\n            macro avg       0.85      0.77      0.80       100\n         weighted avg       0.81      0.79      0.79       100\n\n==================================================\nRandom Forest Accuracy: 0.77\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.72      0.89      0.80        37\ncautiously optimistic       0.73      0.65      0.69        17\n             negative       0.83      0.62      0.71        16\n              neutral       1.00      0.67      0.80         9\n             positive       0.81      0.81      0.81        21\n\n             accuracy                           0.77       100\n            macro avg       0.82      0.73      0.76       100\n         weighted avg       0.78      0.77      0.77       100\n\n==================================================\nGradient Boosting Accuracy: 0.80\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.78      0.86      0.82        37\ncautiously optimistic       0.59      0.76      0.67        17\n             negative       0.93      0.81      0.87        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.94      0.71      0.81        21\n\n             accuracy                           0.80       100\n            macro avg       0.85      0.79      0.81       100\n         weighted avg       0.82      0.80      0.80       100\n\n==================================================\nSVM Accuracy: 0.80\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.72      0.92      0.81        37\ncautiously optimistic       0.72      0.76      0.74        17\n             negative       1.00      0.50      0.67        16\n              neutral       1.00      0.89      0.94         9\n             positive       0.89      0.81      0.85        21\n\n             accuracy                           0.80       100\n            macro avg       0.87      0.78      0.80       100\n         weighted avg       0.83      0.80      0.80       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.80\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.84      0.86      0.85        37\ncautiously optimistic       0.55      0.65      0.59        17\n             negative       0.93      0.81      0.87        16\n              neutral       0.88      0.78      0.82         9\n             positive       0.85      0.81      0.83        21\n\n             accuracy                           0.80       100\n            macro avg       0.81      0.78      0.79       100\n         weighted avg       0.81      0.80      0.80       100\n\n==================================================\nDecision Tree Accuracy: 0.69\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.73      0.72        37\ncautiously optimistic       0.62      0.76      0.68        17\n             negative       0.91      0.62      0.74        16\n              neutral       0.36      0.56      0.43         9\n             positive       0.88      0.67      0.76        21\n\n             accuracy                           0.69       100\n            macro avg       0.69      0.67      0.67       100\n         weighted avg       0.73      0.69      0.70       100\n\n==================================================\nAdaBoost Accuracy: 0.53\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.73      0.65      0.69        37\ncautiously optimistic       0.28      0.53      0.37        17\n             negative       0.67      0.75      0.71        16\n              neutral       0.40      0.44      0.42         9\n             positive       0.57      0.19      0.29        21\n\n             accuracy                           0.53       100\n            macro avg       0.53      0.51      0.49       100\n         weighted avg       0.58      0.53      0.53       100\n\n==================================================\nBagging Classifier Accuracy: 0.77\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.75      0.81      0.78        37\ncautiously optimistic       0.64      0.82      0.72        17\n             negative       0.92      0.75      0.83        16\n              neutral       0.62      0.56      0.59         9\n             positive       0.94      0.76      0.84        21\n\n             accuracy                           0.77       100\n            macro avg       0.78      0.74      0.75       100\n         weighted avg       0.79      0.77      0.77       100\n\n==================================================\nExtra Trees Accuracy: 0.82\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.72      0.92      0.81        37\ncautiously optimistic       0.82      0.82      0.82        17\n             negative       0.91      0.62      0.74        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.94      0.81      0.87        21\n\n             accuracy                           0.82       100\n            macro avg       0.88      0.79      0.82       100\n         weighted avg       0.84      0.82      0.82       100\n\n==================================================\n","output_type":"stream"}]}]}