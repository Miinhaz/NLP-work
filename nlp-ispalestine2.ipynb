{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1874598,"sourceType":"datasetVersion","datasetId":1115942},{"sourceId":4855502,"sourceType":"datasetVersion","datasetId":2814684},{"sourceId":6476455,"sourceType":"datasetVersion","datasetId":3741302},{"sourceId":6477512,"sourceType":"datasetVersion","datasetId":3742034},{"sourceId":6935927,"sourceType":"datasetVersion","datasetId":3982915}],"dockerImageVersionId":30498,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Use TfidfVectorizer to convert text data into numerical features\nvectorizer = TfidfVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Initialize and train the Naive Bayes model\nmodel = MultinomialNB()\nmodel.fit(X_train_tfidf, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test_tfidf)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n# Display classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:03:25.628925Z","iopub.execute_input":"2023-12-07T05:03:25.629704Z","iopub.status.idle":"2023-12-07T05:03:25.671194Z","shell.execute_reply.started":"2023-12-07T05:03:25.629671Z","shell.execute_reply":"2023-12-07T05:03:25.670284Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Accuracy: 0.78\nClassification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.97      0.82        37\ncautiously optimistic       0.83      0.59      0.69        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.44      0.62         9\n             positive       0.77      0.81      0.79        21\n\n             accuracy                           0.78       100\n            macro avg       0.86      0.70      0.75       100\n         weighted avg       0.82      0.78      0.77       100\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Use TfidfVectorizer to convert text data into numerical features\nvectorizer = TfidfVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Initialize and train the Support Vector Machine (SVM) model\nsvm_model = SVC(kernel='linear')  # You can try different kernels, e.g., 'linear', 'rbf', etc.\nsvm_model.fit(X_train_tfidf, y_train)\n\n# Make predictions on the test set\ny_pred_svm = svm_model.predict(X_test_tfidf)\n\n# Evaluate the SVM model\naccuracy_svm = accuracy_score(y_test, y_pred_svm)\nprint(f\"SVM Accuracy: {accuracy_svm:.2f}\")\n\n# Display SVM classification report\nprint(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:06:13.628604Z","iopub.execute_input":"2023-12-07T05:06:13.629404Z","iopub.status.idle":"2023-12-07T05:06:13.769573Z","shell.execute_reply.started":"2023-12-07T05:06:13.629369Z","shell.execute_reply":"2023-12-07T05:06:13.768582Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"SVM Accuracy: 0.87\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      1.00      0.87        37\ncautiously optimistic       0.88      0.88      0.88        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.78      0.88         9\n             positive       1.00      0.81      0.89        21\n\n             accuracy                           0.87       100\n            macro avg       0.93      0.83      0.87       100\n         weighted avg       0.90      0.87      0.87       100\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Use TfidfVectorizer to convert text data into numerical features\nvectorizer = TfidfVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Multinomial Naive Bayes': MultinomialNB(),\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear')\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_tfidf, y_train)\n    y_pred = clf.predict(X_test_tfidf)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:07:48.309207Z","iopub.execute_input":"2023-12-07T05:07:48.309608Z","iopub.status.idle":"2023-12-07T05:07:50.305126Z","shell.execute_reply.started":"2023-12-07T05:07:48.309581Z","shell.execute_reply":"2023-12-07T05:07:50.304185Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Multinomial Naive Bayes Accuracy: 0.78\nMultinomial Naive Bayes Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.97      0.82        37\ncautiously optimistic       0.83      0.59      0.69        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.44      0.62         9\n             positive       0.77      0.81      0.79        21\n\n             accuracy                           0.78       100\n            macro avg       0.86      0.70      0.75       100\n         weighted avg       0.82      0.78      0.77       100\n\n==================================================\nLogistic Regression Accuracy: 0.81\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.70      1.00      0.82        37\ncautiously optimistic       0.86      0.71      0.77        17\n             negative       1.00      0.56      0.72        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.94      0.76      0.84        21\n\n             accuracy                           0.81       100\n            macro avg       0.90      0.76      0.81       100\n         weighted avg       0.85      0.81      0.81       100\n\n==================================================\nRandom Forest Accuracy: 0.82\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.72      0.97      0.83        37\ncautiously optimistic       0.87      0.76      0.81        17\n             negative       1.00      0.50      0.67        16\n              neutral       1.00      0.89      0.94         9\n             positive       0.89      0.81      0.85        21\n\n             accuracy                           0.82       100\n            macro avg       0.90      0.79      0.82       100\n         weighted avg       0.85      0.82      0.81       100\n\n==================================================\nGradient Boosting Accuracy: 0.81\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      0.92      0.84        37\ncautiously optimistic       0.92      0.65      0.76        17\n             negative       1.00      0.69      0.81        16\n              neutral       0.70      0.78      0.74         9\n             positive       0.78      0.86      0.82        21\n\n             accuracy                           0.81       100\n            macro avg       0.83      0.78      0.79       100\n         weighted avg       0.83      0.81      0.81       100\n\n==================================================\nSVM Accuracy: 0.87\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      1.00      0.87        37\ncautiously optimistic       0.88      0.88      0.88        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.78      0.88         9\n             positive       1.00      0.81      0.89        21\n\n             accuracy                           0.87       100\n            macro avg       0.93      0.83      0.87       100\n         weighted avg       0.90      0.87      0.87       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Use TfidfVectorizer to convert text data into numerical features\nvectorizer = TfidfVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Multinomial Naive Bayes': MultinomialNB(),\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_tfidf, y_train)\n    y_pred = clf.predict(X_test_tfidf)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:09:14.835909Z","iopub.execute_input":"2023-12-07T05:09:14.836976Z","iopub.status.idle":"2023-12-07T05:09:17.313441Z","shell.execute_reply.started":"2023-12-07T05:09:14.836938Z","shell.execute_reply":"2023-12-07T05:09:17.312498Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Multinomial Naive Bayes Accuracy: 0.78\nMultinomial Naive Bayes Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.97      0.82        37\ncautiously optimistic       0.83      0.59      0.69        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.44      0.62         9\n             positive       0.77      0.81      0.79        21\n\n             accuracy                           0.78       100\n            macro avg       0.86      0.70      0.75       100\n         weighted avg       0.82      0.78      0.77       100\n\n==================================================\nLogistic Regression Accuracy: 0.81\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.70      1.00      0.82        37\ncautiously optimistic       0.86      0.71      0.77        17\n             negative       1.00      0.56      0.72        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.94      0.76      0.84        21\n\n             accuracy                           0.81       100\n            macro avg       0.90      0.76      0.81       100\n         weighted avg       0.85      0.81      0.81       100\n\n==================================================\nRandom Forest Accuracy: 0.83\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.75      0.97      0.85        37\ncautiously optimistic       0.93      0.76      0.84        17\n             negative       1.00      0.56      0.72        16\n              neutral       0.80      0.89      0.84         9\n             positive       0.89      0.81      0.85        21\n\n             accuracy                           0.83       100\n            macro avg       0.87      0.80      0.82       100\n         weighted avg       0.86      0.83      0.83       100\n\n==================================================\nGradient Boosting Accuracy: 0.81\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      0.92      0.84        37\ncautiously optimistic       0.92      0.65      0.76        17\n             negative       1.00      0.69      0.81        16\n              neutral       0.70      0.78      0.74         9\n             positive       0.78      0.86      0.82        21\n\n             accuracy                           0.81       100\n            macro avg       0.83      0.78      0.79       100\n         weighted avg       0.83      0.81      0.81       100\n\n==================================================\nSVM Accuracy: 0.87\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      1.00      0.87        37\ncautiously optimistic       0.88      0.88      0.88        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.78      0.88         9\n             positive       1.00      0.81      0.89        21\n\n             accuracy                           0.87       100\n            macro avg       0.93      0.83      0.87       100\n         weighted avg       0.90      0.87      0.87       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.80\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      0.92      0.84        37\ncautiously optimistic       0.86      0.71      0.77        17\n             negative       0.92      0.69      0.79        16\n              neutral       0.67      0.67      0.67         9\n             positive       0.81      0.81      0.81        21\n\n             accuracy                           0.80       100\n            macro avg       0.80      0.76      0.78       100\n         weighted avg       0.81      0.80      0.80       100\n\n==================================================\nDecision Tree Accuracy: 0.73\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.75      0.81      0.78        37\ncautiously optimistic       0.75      0.71      0.73        17\n             negative       0.75      0.56      0.64        16\n              neutral       0.58      0.78      0.67         9\n             positive       0.75      0.71      0.73        21\n\n             accuracy                           0.73       100\n            macro avg       0.72      0.71      0.71       100\n         weighted avg       0.73      0.73      0.73       100\n\n==================================================\nAdaBoost Accuracy: 0.48\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.54      0.95      0.69        37\ncautiously optimistic       0.23      0.29      0.26        17\n             negative       0.00      0.00      0.00        16\n              neutral       0.88      0.78      0.82         9\n             positive       0.33      0.05      0.08        21\n\n             accuracy                           0.48       100\n            macro avg       0.39      0.41      0.37       100\n         weighted avg       0.39      0.48      0.39       100\n\n==================================================\nBagging Classifier Accuracy: 0.78\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.74      0.95      0.83        37\ncautiously optimistic       0.79      0.65      0.71        17\n             negative       0.75      0.56      0.64        16\n              neutral       0.89      0.89      0.89         9\n             positive       0.83      0.71      0.77        21\n\n             accuracy                           0.78       100\n            macro avg       0.80      0.75      0.77       100\n         weighted avg       0.78      0.78      0.77       100\n\n==================================================\nExtra Trees Accuracy: 0.86\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.79      1.00      0.88        37\ncautiously optimistic       0.88      0.82      0.85        17\n             negative       1.00      0.69      0.81        16\n              neutral       0.88      0.78      0.82         9\n             positive       0.94      0.81      0.87        21\n\n             accuracy                           0.86       100\n            macro avg       0.90      0.82      0.85       100\n         weighted avg       0.88      0.86      0.86       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n\n# Use TfidfVectorizer to convert text data into numerical features\nvectorizer = TfidfVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Multinomial Naive Bayes': MultinomialNB(),\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_tfidf, y_train)\n    y_pred = clf.predict(X_test_tfidf)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:14:44.517401Z","iopub.execute_input":"2023-12-07T05:14:44.517822Z","iopub.status.idle":"2023-12-07T05:14:46.902180Z","shell.execute_reply.started":"2023-12-07T05:14:44.517788Z","shell.execute_reply":"2023-12-07T05:14:46.901205Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Multinomial Naive Bayes Accuracy: 0.85\nMultinomial Naive Bayes Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.72      1.00      0.84        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.95      0.90      0.92        20\n              neutral       1.00      0.50      0.67        12\n             positive       0.86      0.83      0.84        23\n\n             accuracy                           0.85       100\n            macro avg       0.89      0.81      0.83       100\n         weighted avg       0.87      0.85      0.85       100\n\n==================================================\nLogistic Regression Accuracy: 0.89\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.74      1.00      0.85        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.95      0.90      0.92        20\n              neutral       1.00      0.83      0.91        12\n             positive       1.00      0.83      0.90        23\n\n             accuracy                           0.89       100\n            macro avg       0.93      0.88      0.90       100\n         weighted avg       0.91      0.89      0.89       100\n\n==================================================\nRandom Forest Accuracy: 0.87\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.73      0.92      0.81        26\ncautiously optimistic       0.89      0.89      0.89        19\n             negative       1.00      0.80      0.89        20\n              neutral       0.91      0.83      0.87        12\n             positive       0.95      0.87      0.91        23\n\n             accuracy                           0.87       100\n            macro avg       0.90      0.86      0.88       100\n         weighted avg       0.89      0.87      0.87       100\n\n==================================================\nGradient Boosting Accuracy: 0.88\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.88      0.85      0.86        26\ncautiously optimistic       0.80      0.84      0.82        19\n             negative       0.90      0.90      0.90        20\n              neutral       0.77      0.83      0.80        12\n             positive       1.00      0.96      0.98        23\n\n             accuracy                           0.88       100\n            macro avg       0.87      0.88      0.87       100\n         weighted avg       0.88      0.88      0.88       100\n\n==================================================\nSVM Accuracy: 0.90\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.79      1.00      0.88        26\ncautiously optimistic       0.89      0.84      0.86        19\n             negative       0.95      0.90      0.92        20\n              neutral       1.00      0.83      0.91        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.90       100\n            macro avg       0.92      0.89      0.90       100\n         weighted avg       0.91      0.90      0.90       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.87\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.76      0.96      0.85        26\ncautiously optimistic       0.85      0.89      0.87        19\n             negative       0.94      0.85      0.89        20\n              neutral       1.00      0.75      0.86        12\n             positive       0.95      0.83      0.88        23\n\n             accuracy                           0.87       100\n            macro avg       0.90      0.86      0.87       100\n         weighted avg       0.89      0.87      0.87       100\n\n==================================================\nDecision Tree Accuracy: 0.81\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.79      0.88      0.84        26\ncautiously optimistic       0.87      0.68      0.76        19\n             negative       0.70      0.80      0.74        20\n              neutral       0.85      0.92      0.88        12\n             positive       0.90      0.78      0.84        23\n\n             accuracy                           0.81       100\n            macro avg       0.82      0.81      0.81       100\n         weighted avg       0.82      0.81      0.81       100\n\n==================================================\nAdaBoost Accuracy: 0.53\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.36      0.92      0.52        26\ncautiously optimistic       0.60      0.16      0.25        19\n             negative       0.00      0.00      0.00        20\n              neutral       0.83      0.83      0.83        12\n             positive       1.00      0.70      0.82        23\n\n             accuracy                           0.53       100\n            macro avg       0.56      0.52      0.48       100\n         weighted avg       0.54      0.53      0.47       100\n\n==================================================\nBagging Classifier Accuracy: 0.79\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.76      0.73      0.75        26\ncautiously optimistic       0.80      0.84      0.82        19\n             negative       0.82      0.70      0.76        20\n              neutral       0.73      0.92      0.81        12\n             positive       0.83      0.83      0.83        23\n\n             accuracy                           0.79       100\n            macro avg       0.79      0.80      0.79       100\n         weighted avg       0.79      0.79      0.79       100\n\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Extra Trees Accuracy: 0.89\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      0.92      0.84        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.95      0.95      0.95        20\n              neutral       0.83      0.83      0.83        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.89       100\n            macro avg       0.90      0.88      0.89       100\n         weighted avg       0.90      0.89      0.89       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n\n# Use CountVectorizer to convert text data into numerical features\nvectorizer = CountVectorizer(max_features=9000)  # You can adjust max_features as needed\nX_train_count = vectorizer.fit_transform(X_train)\nX_test_count = vectorizer.transform(X_test)\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Multinomial Naive Bayes': MultinomialNB(),\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_count, y_train)\n    y_pred = clf.predict(X_test_count)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:17:03.069633Z","iopub.execute_input":"2023-12-07T05:17:03.070065Z","iopub.status.idle":"2023-12-07T05:17:05.022260Z","shell.execute_reply.started":"2023-12-07T05:17:03.070034Z","shell.execute_reply":"2023-12-07T05:17:05.021357Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Multinomial Naive Bayes Accuracy: 0.88\nMultinomial Naive Bayes Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.80      0.92      0.86        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.83      0.95      0.88        20\n              neutral       1.00      0.83      0.91        12\n             positive       0.95      0.83      0.88        23\n\n             accuracy                           0.88       100\n            macro avg       0.90      0.87      0.88       100\n         weighted avg       0.89      0.88      0.88       100\n\n==================================================\nLogistic Regression Accuracy: 0.89\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.78      0.96      0.86        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.90      0.90      0.90        20\n              neutral       0.91      0.83      0.87        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.89       100\n            macro avg       0.91      0.88      0.89       100\n         weighted avg       0.90      0.89      0.89       100\n\n==================================================\nRandom Forest Accuracy: 0.91\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.76      0.96      0.85        26\ncautiously optimistic       1.00      0.89      0.94        19\n             negative       1.00      0.90      0.95        20\n              neutral       0.91      0.83      0.87        12\n             positive       1.00      0.91      0.95        23\n\n             accuracy                           0.91       100\n            macro avg       0.93      0.90      0.91       100\n         weighted avg       0.93      0.91      0.91       100\n\n==================================================\nGradient Boosting Accuracy: 0.89\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.86      0.92      0.89        26\ncautiously optimistic       0.76      0.84      0.80        19\n             negative       0.90      0.95      0.93        20\n              neutral       1.00      0.83      0.91        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.89       100\n            macro avg       0.90      0.88      0.89       100\n         weighted avg       0.90      0.89      0.89       100\n\n==================================================\nSVM Accuracy: 0.87\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.79      0.88      0.84        26\ncautiously optimistic       0.80      0.84      0.82        19\n             negative       0.95      0.90      0.92        20\n              neutral       0.83      0.83      0.83        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.87       100\n            macro avg       0.87      0.87      0.87       100\n         weighted avg       0.88      0.87      0.87       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.77\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.73      0.85      0.79        26\ncautiously optimistic       0.78      0.74      0.76        19\n             negative       0.82      0.70      0.76        20\n              neutral       0.80      0.67      0.73        12\n             positive       0.76      0.83      0.79        23\n\n             accuracy                           0.77       100\n            macro avg       0.78      0.76      0.76       100\n         weighted avg       0.77      0.77      0.77       100\n\n==================================================\nDecision Tree Accuracy: 0.84\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.83      0.96      0.89        26\ncautiously optimistic       0.76      0.68      0.72        19\n             negative       0.88      0.75      0.81        20\n              neutral       0.77      0.83      0.80        12\n             positive       0.91      0.91      0.91        23\n\n             accuracy                           0.84       100\n            macro avg       0.83      0.83      0.83       100\n         weighted avg       0.84      0.84      0.84       100\n\n==================================================\nAdaBoost Accuracy: 0.54\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.43      0.85      0.57        26\ncautiously optimistic       0.60      0.32      0.41        19\n             negative       0.62      0.50      0.56        20\n              neutral       0.58      0.58      0.58        12\n             positive       0.82      0.39      0.53        23\n\n             accuracy                           0.54       100\n            macro avg       0.61      0.53      0.53       100\n         weighted avg       0.61      0.54      0.53       100\n\n==================================================\nBagging Classifier Accuracy: 0.87\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.77      0.88      0.82        26\ncautiously optimistic       0.89      0.84      0.86        19\n             negative       0.86      0.90      0.88        20\n              neutral       0.91      0.83      0.87        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.87       100\n            macro avg       0.88      0.87      0.87       100\n         weighted avg       0.88      0.87      0.87       100\n\n==================================================\nExtra Trees Accuracy: 0.88\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.75      0.92      0.83        26\ncautiously optimistic       0.94      0.84      0.89        19\n             negative       0.95      0.90      0.92        20\n              neutral       0.83      0.83      0.83        12\n             positive       1.00      0.87      0.93        23\n\n             accuracy                           0.88       100\n            macro avg       0.89      0.87      0.88       100\n         weighted avg       0.89      0.88      0.88       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom gensim.models import Word2Vec\nfrom gensim.models.doc2vec import TaggedDocument\nfrom nltk.tokenize import word_tokenize\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Tokenize the text data\ntokenized_X_train = [word_tokenize(text) for text in X_train]\ntokenized_X_test = [word_tokenize(text) for text in X_test]\n\n# Train Word2Vec model\nword2vec_model = Word2Vec(sentences=tokenized_X_train, vector_size=100, window=5, min_count=1, workers=4)\n\n# Function to create document vectors using Word2Vec model\ndef create_doc_vectors(tokenized_text, model):\n    vectors = [model.wv[word] for word in tokenized_text if word in model.wv]\n    return sum(vectors) / len(vectors) if vectors else [0] * model.vector_size\n\n# Create document vectors for training and testing sets\nX_train_w2v = [create_doc_vectors(tokens, word2vec_model) for tokens in tokenized_X_train]\nX_test_w2v = [create_doc_vectors(tokens, word2vec_model) for tokens in tokenized_X_test]\n\n# Convert to numpy arrays\nX_train_w2v = pd.DataFrame(X_train_w2v).to_numpy()\nX_test_w2v = pd.DataFrame(X_test_w2v).to_numpy()\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_w2v, y_train)\n    y_pred = clf.predict(X_test_w2v)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:18:45.427457Z","iopub.execute_input":"2023-12-07T05:18:45.428093Z","iopub.status.idle":"2023-12-07T05:18:51.788853Z","shell.execute_reply.started":"2023-12-07T05:18:45.428060Z","shell.execute_reply":"2023-12-07T05:18:51.787867Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Logistic Regression Accuracy: 0.33\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.37      0.84      0.52        37\ncautiously optimistic       0.00      0.00      0.00        17\n             negative       0.00      0.00      0.00        16\n              neutral       0.00      0.00      0.00         9\n             positive       0.12      0.10      0.11        21\n\n             accuracy                           0.33       100\n            macro avg       0.10      0.19      0.12       100\n         weighted avg       0.16      0.33      0.21       100\n\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Random Forest Accuracy: 0.67\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.67      0.81      0.73        37\ncautiously optimistic       0.82      0.53      0.64        17\n             negative       0.73      0.50      0.59        16\n              neutral       0.40      0.67      0.50         9\n             positive       0.78      0.67      0.72        21\n\n             accuracy                           0.67       100\n            macro avg       0.68      0.63      0.64       100\n         weighted avg       0.70      0.67      0.67       100\n\n==================================================\nGradient Boosting Accuracy: 0.66\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.74      0.76      0.75        37\ncautiously optimistic       0.55      0.65      0.59        17\n             negative       0.64      0.44      0.52        16\n              neutral       0.45      0.56      0.50         9\n             positive       0.75      0.71      0.73        21\n\n             accuracy                           0.66       100\n            macro avg       0.63      0.62      0.62       100\n         weighted avg       0.67      0.66      0.66       100\n\n==================================================\nSVM Accuracy: 0.37\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.37      1.00      0.54        37\ncautiously optimistic       0.00      0.00      0.00        17\n             negative       0.00      0.00      0.00        16\n              neutral       0.00      0.00      0.00         9\n             positive       0.00      0.00      0.00        21\n\n             accuracy                           0.37       100\n            macro avg       0.07      0.20      0.11       100\n         weighted avg       0.14      0.37      0.20       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.51\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.53      0.65      0.59        37\ncautiously optimistic       0.44      0.41      0.42        17\n             negative       0.55      0.38      0.44        16\n              neutral       0.25      0.33      0.29         9\n             positive       0.69      0.52      0.59        21\n\n             accuracy                           0.51       100\n            macro avg       0.49      0.46      0.47       100\n         weighted avg       0.53      0.51      0.51       100\n\n==================================================\nDecision Tree Accuracy: 0.57\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.67      0.59      0.63        37\ncautiously optimistic       0.45      0.53      0.49        17\n             negative       0.62      0.50      0.55        16\n              neutral       0.38      0.67      0.48         9\n             positive       0.67      0.57      0.62        21\n\n             accuracy                           0.57       100\n            macro avg       0.55      0.57      0.55       100\n         weighted avg       0.60      0.57      0.58       100\n\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"AdaBoost Accuracy: 0.38\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.45      0.54      0.49        37\ncautiously optimistic       0.26      0.35      0.30        17\n             negative       0.36      0.31      0.33        16\n              neutral       0.20      0.22      0.21         9\n             positive       0.56      0.24      0.33        21\n\n             accuracy                           0.38       100\n            macro avg       0.37      0.33      0.33       100\n         weighted avg       0.40      0.38      0.38       100\n\n==================================================\nBagging Classifier Accuracy: 0.63\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.63      0.73      0.68        37\ncautiously optimistic       0.56      0.59      0.57        17\n             negative       0.73      0.50      0.59        16\n              neutral       0.50      0.56      0.53         9\n             positive       0.72      0.62      0.67        21\n\n             accuracy                           0.63       100\n            macro avg       0.63      0.60      0.61       100\n         weighted avg       0.64      0.63      0.63       100\n\n==================================================\nExtra Trees Accuracy: 0.65\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.64      0.81      0.71        37\ncautiously optimistic       0.90      0.53      0.67        17\n             negative       0.60      0.38      0.46        16\n              neutral       0.40      0.67      0.50         9\n             positive       0.78      0.67      0.72        21\n\n             accuracy                           0.65       100\n            macro avg       0.66      0.61      0.61       100\n         weighted avg       0.68      0.65      0.65       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Load Universal Sentence Encoder\nembed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n\n# Create embeddings for training and testing sets\nX_train_use = embed(X_train)\nX_test_use = embed(X_test)\n\n# Convert TensorFlow tensors to NumPy arrays\nX_train_use = X_train_use.numpy()\nX_test_use = X_test_use.numpy()\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_use, y_train)\n    y_pred = clf.predict(X_test_use)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:21:14.764373Z","iopub.execute_input":"2023-12-07T05:21:14.765113Z","iopub.status.idle":"2023-12-07T05:21:48.011132Z","shell.execute_reply.started":"2023-12-07T05:21:14.765077Z","shell.execute_reply":"2023-12-07T05:21:48.010233Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Logistic Regression Accuracy: 0.79\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.86      0.78        37\ncautiously optimistic       0.71      0.71      0.71        17\n             negative       0.91      0.62      0.74        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.90      0.86      0.88        21\n\n             accuracy                           0.79       100\n            macro avg       0.85      0.77      0.80       100\n         weighted avg       0.81      0.79      0.79       100\n\n==================================================\nRandom Forest Accuracy: 0.77\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.72      0.89      0.80        37\ncautiously optimistic       0.73      0.65      0.69        17\n             negative       0.83      0.62      0.71        16\n              neutral       1.00      0.67      0.80         9\n             positive       0.81      0.81      0.81        21\n\n             accuracy                           0.77       100\n            macro avg       0.82      0.73      0.76       100\n         weighted avg       0.78      0.77      0.77       100\n\n==================================================\nGradient Boosting Accuracy: 0.80\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.78      0.86      0.82        37\ncautiously optimistic       0.59      0.76      0.67        17\n             negative       0.93      0.81      0.87        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.94      0.71      0.81        21\n\n             accuracy                           0.80       100\n            macro avg       0.85      0.79      0.81       100\n         weighted avg       0.82      0.80      0.80       100\n\n==================================================\nSVM Accuracy: 0.80\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.72      0.92      0.81        37\ncautiously optimistic       0.72      0.76      0.74        17\n             negative       1.00      0.50      0.67        16\n              neutral       1.00      0.89      0.94         9\n             positive       0.89      0.81      0.85        21\n\n             accuracy                           0.80       100\n            macro avg       0.87      0.78      0.80       100\n         weighted avg       0.83      0.80      0.80       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.80\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.84      0.86      0.85        37\ncautiously optimistic       0.55      0.65      0.59        17\n             negative       0.93      0.81      0.87        16\n              neutral       0.88      0.78      0.82         9\n             positive       0.85      0.81      0.83        21\n\n             accuracy                           0.80       100\n            macro avg       0.81      0.78      0.79       100\n         weighted avg       0.81      0.80      0.80       100\n\n==================================================\nDecision Tree Accuracy: 0.69\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.73      0.72        37\ncautiously optimistic       0.62      0.76      0.68        17\n             negative       0.91      0.62      0.74        16\n              neutral       0.36      0.56      0.43         9\n             positive       0.88      0.67      0.76        21\n\n             accuracy                           0.69       100\n            macro avg       0.69      0.67      0.67       100\n         weighted avg       0.73      0.69      0.70       100\n\n==================================================\nAdaBoost Accuracy: 0.53\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.73      0.65      0.69        37\ncautiously optimistic       0.28      0.53      0.37        17\n             negative       0.67      0.75      0.71        16\n              neutral       0.40      0.44      0.42         9\n             positive       0.57      0.19      0.29        21\n\n             accuracy                           0.53       100\n            macro avg       0.53      0.51      0.49       100\n         weighted avg       0.58      0.53      0.53       100\n\n==================================================\nBagging Classifier Accuracy: 0.77\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.75      0.81      0.78        37\ncautiously optimistic       0.64      0.82      0.72        17\n             negative       0.92      0.75      0.83        16\n              neutral       0.62      0.56      0.59         9\n             positive       0.94      0.76      0.84        21\n\n             accuracy                           0.77       100\n            macro avg       0.78      0.74      0.75       100\n         weighted avg       0.79      0.77      0.77       100\n\n==================================================\nExtra Trees Accuracy: 0.82\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.72      0.92      0.81        37\ncautiously optimistic       0.82      0.82      0.82        17\n             negative       0.91      0.62      0.74        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.94      0.81      0.87        21\n\n             accuracy                           0.82       100\n            macro avg       0.88      0.79      0.82       100\n         weighted avg       0.84      0.82      0.82       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:23:32.004944Z","iopub.execute_input":"2023-12-07T05:23:32.005355Z","iopub.status.idle":"2023-12-07T05:23:43.712922Z","shell.execute_reply.started":"2023-12-07T05:23:32.005325Z","shell.execute_reply":"2023-12-07T05:23:43.711663Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.29.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom transformers import BertTokenizer, BertModel\nimport torch\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Load pre-trained BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n\n# Tokenize and convert text to BERT embeddings for training set\nX_train_bert = [tokenizer(text, return_tensors='pt', truncation=True, padding=True) for text in X_train]\nX_train_bert_embeddings = torch.stack([model(**tokens)['last_hidden_state'].mean(dim=1).squeeze() for tokens in X_train_bert])\n\n# Tokenize and convert text to BERT embeddings for testing set\nX_test_bert = [tokenizer(text, return_tensors='pt', truncation=True, padding=True) for text in X_test]\nX_test_bert_embeddings = torch.stack([model(**tokens)['last_hidden_state'].mean(dim=1).squeeze() for tokens in X_test_bert])\n\n# Convert to NumPy arrays\nX_train_bert_embeddings = X_train_bert_embeddings.detach().numpy()\nX_test_bert_embeddings = X_test_bert_embeddings.detach().numpy()\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_bert_embeddings, y_train)\n    y_pred = clf.predict(X_test_bert_embeddings)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:25:23.615068Z","iopub.execute_input":"2023-12-07T05:25:23.616059Z","iopub.status.idle":"2023-12-07T05:26:33.907217Z","shell.execute_reply.started":"2023-12-07T05:25:23.616016Z","shell.execute_reply":"2023-12-07T05:26:33.906183Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Logistic Regression Accuracy: 0.85\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.81      0.92      0.86        37\ncautiously optimistic       0.82      0.82      0.82        17\n             negative       0.92      0.75      0.83        16\n              neutral       0.80      0.89      0.84         9\n             positive       0.94      0.81      0.87        21\n\n             accuracy                           0.85       100\n            macro avg       0.86      0.84      0.85       100\n         weighted avg       0.86      0.85      0.85       100\n\n==================================================\nRandom Forest Accuracy: 0.82\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.73      0.95      0.82        37\ncautiously optimistic       0.76      0.76      0.76        17\n             negative       1.00      0.62      0.77        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.94      0.81      0.87        21\n\n             accuracy                           0.82       100\n            macro avg       0.89      0.78      0.82       100\n         weighted avg       0.85      0.82      0.82       100\n\n==================================================\nGradient Boosting Accuracy: 0.80\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.76      0.86      0.81        37\ncautiously optimistic       0.76      0.76      0.76        17\n             negative       0.92      0.69      0.79        16\n              neutral       0.73      0.89      0.80         9\n             positive       0.89      0.76      0.82        21\n\n             accuracy                           0.80       100\n            macro avg       0.81      0.79      0.80       100\n         weighted avg       0.81      0.80      0.80       100\n\n==================================================\nSVM Accuracy: 0.88\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.80      0.97      0.88        37\ncautiously optimistic       0.83      0.88      0.86        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.89      0.94         9\n             positive       1.00      0.86      0.92        21\n\n             accuracy                           0.88       100\n            macro avg       0.93      0.86      0.88       100\n         weighted avg       0.90      0.88      0.88       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom transformers import BertTokenizer, BertModel\nimport torch\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Load pre-trained BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n\n# Tokenize and convert text to BERT embeddings for training set\nX_train_bert = [tokenizer(text, return_tensors='pt', truncation=True, padding=True) for text in X_train]\nX_train_bert_embeddings = torch.stack([model(**tokens)['last_hidden_state'].mean(dim=1).squeeze() for tokens in X_train_bert])\n\n# Tokenize and convert text to BERT embeddings for testing set\nX_test_bert = [tokenizer(text, return_tensors='pt', truncation=True, padding=True) for text in X_test]\nX_test_bert_embeddings = torch.stack([model(**tokens)['last_hidden_state'].mean(dim=1).squeeze() for tokens in X_test_bert])\n\n# Convert to NumPy arrays\nX_train_bert_embeddings = X_train_bert_embeddings.detach().numpy()\nX_test_bert_embeddings = X_test_bert_embeddings.detach().numpy()\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier(),\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_bert_embeddings, y_train)\n    y_pred = clf.predict(X_test_bert_embeddings)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:28:32.296133Z","iopub.execute_input":"2023-12-07T05:28:32.297047Z","iopub.status.idle":"2023-12-07T05:29:48.278799Z","shell.execute_reply.started":"2023-12-07T05:28:32.297009Z","shell.execute_reply":"2023-12-07T05:29:48.277573Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Logistic Regression Accuracy: 0.85\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.81      0.92      0.86        37\ncautiously optimistic       0.82      0.82      0.82        17\n             negative       0.92      0.75      0.83        16\n              neutral       0.80      0.89      0.84         9\n             positive       0.94      0.81      0.87        21\n\n             accuracy                           0.85       100\n            macro avg       0.86      0.84      0.85       100\n         weighted avg       0.86      0.85      0.85       100\n\n==================================================\nRandom Forest Accuracy: 0.80\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.69      0.92      0.79        37\ncautiously optimistic       0.81      0.76      0.79        17\n             negative       1.00      0.56      0.72        16\n              neutral       1.00      0.78      0.88         9\n             positive       0.89      0.81      0.85        21\n\n             accuracy                           0.80       100\n            macro avg       0.88      0.77      0.80       100\n         weighted avg       0.83      0.80      0.80       100\n\n==================================================\nGradient Boosting Accuracy: 0.80\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.76      0.86      0.81        37\ncautiously optimistic       0.76      0.76      0.76        17\n             negative       0.92      0.69      0.79        16\n              neutral       0.73      0.89      0.80         9\n             positive       0.89      0.76      0.82        21\n\n             accuracy                           0.80       100\n            macro avg       0.81      0.79      0.80       100\n         weighted avg       0.81      0.80      0.80       100\n\n==================================================\nSVM Accuracy: 0.88\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.80      0.97      0.88        37\ncautiously optimistic       0.83      0.88      0.86        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.89      0.94         9\n             positive       1.00      0.86      0.92        21\n\n             accuracy                           0.88       100\n            macro avg       0.93      0.86      0.88       100\n         weighted avg       0.90      0.88      0.88       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.79\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.71      0.92      0.80        37\ncautiously optimistic       0.71      0.71      0.71        17\n             negative       1.00      0.62      0.77        16\n              neutral       1.00      0.67      0.80         9\n             positive       0.89      0.81      0.85        21\n\n             accuracy                           0.79       100\n            macro avg       0.86      0.75      0.79       100\n         weighted avg       0.82      0.79      0.79       100\n\n==================================================\nDecision Tree Accuracy: 0.69\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.74      0.78      0.76        37\ncautiously optimistic       0.64      0.53      0.58        17\n             negative       0.78      0.44      0.56        16\n              neutral       0.58      0.78      0.67         9\n             positive       0.65      0.81      0.72        21\n\n             accuracy                           0.69       100\n            macro avg       0.68      0.67      0.66       100\n         weighted avg       0.70      0.69      0.68       100\n\n==================================================\nAdaBoost Accuracy: 0.48\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.50      0.46      0.48        37\ncautiously optimistic       0.56      0.53      0.55        17\n             negative       0.21      0.38      0.27        16\n              neutral       1.00      0.22      0.36         9\n             positive       0.74      0.67      0.70        21\n\n             accuracy                           0.48       100\n            macro avg       0.60      0.45      0.47       100\n         weighted avg       0.56      0.48      0.49       100\n\n==================================================\nBagging Classifier Accuracy: 0.77\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.70      0.89      0.79        37\ncautiously optimistic       0.80      0.71      0.75        17\n             negative       0.82      0.56      0.67        16\n              neutral       0.86      0.67      0.75         9\n             positive       0.85      0.81      0.83        21\n\n             accuracy                           0.77       100\n            macro avg       0.81      0.73      0.76       100\n         weighted avg       0.78      0.77      0.77       100\n\n==================================================\nExtra Trees Accuracy: 0.85\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.75      0.97      0.85        37\ncautiously optimistic       0.87      0.76      0.81        17\n             negative       1.00      0.69      0.81        16\n              neutral       1.00      0.89      0.94         9\n             positive       0.94      0.81      0.87        21\n\n             accuracy                           0.85       100\n            macro avg       0.91      0.82      0.86       100\n         weighted avg       0.87      0.85      0.85       100\n\n==================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 59\u001b[0m\n\u001b[1;32m     44\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m'\u001b[39m: LogisticRegression(),\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestClassifier(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLightGBM\u001b[39m\u001b[38;5;124m'\u001b[39m: LGBMClassifier(),\n\u001b[1;32m     56\u001b[0m }\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clf_name, clf \u001b[38;5;129;01min\u001b[39;00m classifiers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_bert_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test_bert_embeddings)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Evaluate the classifier\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:1440\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1435\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1439\u001b[0m ):\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1442\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1443\u001b[0m     )\n\u001b[1;32m   1445\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n","\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got ['ambivalent' 'cautiously optimistic' 'negative' 'neutral' 'positive']"],"ename":"ValueError","evalue":"Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got ['ambivalent' 'cautiously optimistic' 'negative' 'neutral' 'positive']","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom nltk.tokenize import word_tokenize\nimport nltk\nnltk.download('punkt')\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Tokenize the text data\ntokenized_X_train = [word_tokenize(text.lower()) for text in X_train]\ntokenized_X_test = [word_tokenize(text.lower()) for text in X_test]\n\n# Create TaggedDocuments for training\ntagged_data_train = [TaggedDocument(words=doc, tags=[str(i)]) for i, doc in enumerate(tokenized_X_train)]\n\n# Create Doc2Vec model\ndoc2vec_model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\ndoc2vec_model.build_vocab(tagged_data_train)\ndoc2vec_model.train(tagged_data_train, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n\n# Transform documents to vectors for training set\nX_train_doc2vec = [doc2vec_model.infer_vector(tokens) for tokens in tokenized_X_train]\n\n# Transform documents to vectors for testing set\nX_test_doc2vec = [doc2vec_model.infer_vector(tokens) for tokens in tokenized_X_test]\n\n# Convert to NumPy arrays\nX_train_doc2vec = pd.DataFrame(X_train_doc2vec).to_numpy()\nX_test_doc2vec = pd.DataFrame(X_test_doc2vec).to_numpy()\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier(),\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_doc2vec, y_train)\n    y_pred = clf.predict(X_test_doc2vec)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:35:36.176953Z","iopub.execute_input":"2023-12-07T05:35:36.177929Z","iopub.status.idle":"2023-12-07T05:35:44.118468Z","shell.execute_reply.started":"2023-12-07T05:35:36.177892Z","shell.execute_reply":"2023-12-07T05:35:44.117557Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nLogistic Regression Accuracy: 0.31\nLogistic Regression Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.35      0.62      0.45        37\ncautiously optimistic       0.00      0.00      0.00        17\n             negative       0.00      0.00      0.00        16\n              neutral       0.00      0.00      0.00         9\n             positive       0.23      0.38      0.29        21\n\n             accuracy                           0.31       100\n            macro avg       0.12      0.20      0.15       100\n         weighted avg       0.18      0.31      0.23       100\n\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Random Forest Accuracy: 0.56\nRandom Forest Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.48      0.73      0.58        37\ncautiously optimistic       0.43      0.35      0.39        17\n             negative       0.83      0.31      0.45        16\n              neutral       0.20      0.11      0.14         9\n             positive       0.89      0.81      0.85        21\n\n             accuracy                           0.56       100\n            macro avg       0.57      0.46      0.48       100\n         weighted avg       0.59      0.56      0.54       100\n\n==================================================\nGradient Boosting Accuracy: 0.56\nGradient Boosting Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.55      0.65      0.59        37\ncautiously optimistic       0.54      0.41      0.47        17\n             negative       0.47      0.50      0.48        16\n              neutral       0.38      0.33      0.35         9\n             positive       0.78      0.67      0.72        21\n\n             accuracy                           0.56       100\n            macro avg       0.54      0.51      0.52       100\n         weighted avg       0.57      0.56      0.56       100\n\n==================================================\nSVM Accuracy: 0.37\nSVM Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.37      1.00      0.54        37\ncautiously optimistic       0.00      0.00      0.00        17\n             negative       0.00      0.00      0.00        16\n              neutral       0.00      0.00      0.00         9\n             positive       0.00      0.00      0.00        21\n\n             accuracy                           0.37       100\n            macro avg       0.07      0.20      0.11       100\n         weighted avg       0.14      0.37      0.20       100\n\n==================================================\nK-Nearest Neighbors Accuracy: 0.38\nK-Nearest Neighbors Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.44      0.65      0.52        37\ncautiously optimistic       0.33      0.24      0.28        17\n             negative       0.25      0.19      0.21        16\n              neutral       0.00      0.00      0.00         9\n             positive       0.47      0.33      0.39        21\n\n             accuracy                           0.38       100\n            macro avg       0.30      0.28      0.28       100\n         weighted avg       0.36      0.38      0.36       100\n\n==================================================\nDecision Tree Accuracy: 0.40\nDecision Tree Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.49      0.46      0.47        37\ncautiously optimistic       0.31      0.47      0.37        17\n             negative       0.31      0.25      0.28        16\n              neutral       0.12      0.11      0.12         9\n             positive       0.56      0.48      0.51        21\n\n             accuracy                           0.40       100\n            macro avg       0.36      0.35      0.35       100\n         weighted avg       0.41      0.40      0.40       100\n\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"AdaBoost Accuracy: 0.45\nAdaBoost Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.49      0.59      0.54        37\ncautiously optimistic       0.30      0.35      0.32        17\n             negative       0.56      0.31      0.40        16\n              neutral       0.23      0.33      0.27         9\n             positive       0.69      0.43      0.53        21\n\n             accuracy                           0.45       100\n            macro avg       0.45      0.40      0.41       100\n         weighted avg       0.49      0.45      0.45       100\n\n==================================================\nBagging Classifier Accuracy: 0.48\nBagging Classifier Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.52      0.59      0.56        37\ncautiously optimistic       0.42      0.59      0.49        17\n             negative       0.42      0.31      0.36        16\n              neutral       0.12      0.11      0.12         9\n             positive       0.71      0.48      0.57        21\n\n             accuracy                           0.48       100\n            macro avg       0.44      0.42      0.42       100\n         weighted avg       0.49      0.48      0.48       100\n\n==================================================\nExtra Trees Accuracy: 0.54\nExtra Trees Classification Report:\n                        precision    recall  f1-score   support\n\n           ambivalent       0.50      0.70      0.58        37\ncautiously optimistic       0.35      0.35      0.35        17\n             negative       0.78      0.44      0.56        16\n              neutral       0.20      0.11      0.14         9\n             positive       0.82      0.67      0.74        21\n\n             accuracy                           0.54       100\n            macro avg       0.53      0.45      0.48       100\n         weighted avg       0.56      0.54      0.53       100\n\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom gensim import corpora\nfrom gensim.models import LdaModel\nfrom nltk.tokenize import word_tokenize\nimport nltk\nnltk.download('punkt')\n\n# Load the dataset with proper tab-separated values\ndf = pd.read_csv('/kaggle/input/conflict2/conflict.tsv', delimiter='\\t')\n\n# Assuming you have a 'text' column for input and a 'label' column for output\n# Replace 'text' and 'label' with your actual column names\nX = df['text']\ny = df['sentiment']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Tokenize the text data\ntokenized_X_train = [word_tokenize(text.lower()) for text in X_train]\ntokenized_X_test = [word_tokenize(text.lower()) for text in X_test]\n\n# Create a dictionary representation of the documents\ndictionary = corpora.Dictionary(tokenized_X_train)\n\n# Convert the tokenized documents into a document-term matrix\ncorpus = [dictionary.doc2bow(tokens) for tokens in tokenized_X_train]\n\n# Train LDA model\nlda_model = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10)\n\n# Transform documents to topic distributions for training set\nX_train_lda = [lda_model[dictionary.doc2bow(tokens)] for tokens in tokenized_X_train]\nX_train_lda = [[topic[1] for topic in doc] for doc in X_train_lda]\n\n# Transform documents to topic distributions for testing set\nX_test_lda = [lda_model[dictionary.doc2bow(tokens)] for tokens in tokenized_X_test]\nX_test_lda = [[topic[1] for topic in doc] for doc in X_test_lda]\n\n# Convert to NumPy arrays\nX_train_lda = pd.DataFrame(X_train_lda).to_numpy()\nX_test_lda = pd.DataFrame(X_test_lda).to_numpy()\n\n# Initialize and train different classifiers\nclassifiers = {\n    'Logistic Regression': LogisticRegression(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(kernel='linear'),\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Bagging Classifier': BaggingClassifier(),\n    'Extra Trees': ExtraTreesClassifier()\n}\n\nfor clf_name, clf in classifiers.items():\n    clf.fit(X_train_lda, y_train)\n    y_pred = clf.predict(X_test_lda)\n\n    # Evaluate the classifier\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy:.2f}\")\n\n    # Display classification report\n    print(f\"{clf_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"=\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:37:02.525657Z","iopub.execute_input":"2023-12-07T05:37:02.526372Z","iopub.status.idle":"2023-12-07T05:37:06.573841Z","shell.execute_reply.started":"2023-12-07T05:37:02.526338Z","shell.execute_reply":"2023-12-07T05:37:06.572367Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 69\u001b[0m\n\u001b[1;32m     56\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m'\u001b[39m: LogisticRegression(),\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestClassifier(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtra Trees\u001b[39m\u001b[38;5;124m'\u001b[39m: ExtraTreesClassifier()\n\u001b[1;32m     66\u001b[0m }\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clf_name, clf \u001b[38;5;129;01min\u001b[39;00m classifiers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 69\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_lda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test_lda)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Evaluate the classifier\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"],"ename":"ValueError","evalue":"Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values","output_type":"error"}]}]}